---
title: "R_0725"
author: "York Lin"
date: "2017年7月25日"
output: html_document
---
## Learning map
- http://scikit-learn.org/stable/_static/ml_map.png

- http://www.r-bloggers.com/whats-the-difference-between-machine-learning-statistics-and-data-mining/

- http://mp.weixin.qq.com/s?__biz=MjM5ODczNTkwMA==&mid=2650107069&idx=1&sn=44a2eab6c4858c56af236749fdd1d784#rd

# Classification
## Decision Tree - using churn data in C50 package
```{R}
install.packages("C50")
library(C50)

data(churn)
str(churnTrain)

names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
#選擇建模變數  (資料清理  除了3個欄位以外的資料儲存進入variable.list裡)
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]

str(churnTrain)

#sample
?sample
sample(1:10)
sample(1:10, size = 5)
sample(c(0,1), size= 10, replace = T)
sample.int(20, 12) # 兩個參數都要放整數，此例為取1:20中的12個不重複樣本


set.seed(2)
#以Sample  -> 將churnTrain資料，分成二筆training data 和 testing data   replace=T ->抽起來會放回去
ind<-sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]


table(sample(x = 1:2,size = 100, replace=T))

#種子模型  每次抽依種子重建
set.seed(1)

table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))

a = c(1,2,3,4,5,6,7,8,9)
ind = c(1,0,1,0,1,0,1,0,1)
ind == 1
a[ind == 1]
a[ind == 0]

```

## rpart
```{R}
install.packages('rpart')
library('rpart')
#使用rpart(CART)建立決策樹模型
#churn~.,data=trainset    trainset資料中除了churn以外的解釋變數都放入建模

churn.rp<-rpart(churn ~ ., data=trainset)
churn.rp
summary(churn.rp)

#事前修剪
con = rpart.control(cp=0.01)
?rpart.control
churn.rp<-rpart(churn ~., data=trainset,control = con)

#畫出決策樹
par(mfrow=c(1,1))
plot(churn.rp, margin=0.1)
plot(churn.rp, uniform=TRUE,branch = 1, margin=0.1)
text(churn.rp, all=TRUE, use.n=TRUE, cex=0.7)
?plot.rpart
text(churn.rp)
text(churn.rp, all=TRUE, use.n=TRUE)

printcp(churn.rp)
plotcp(churn.rp)
```

## Prune
```{R}
#找出minimum cross-validation errors
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
#將churn.cp設為臨界值來修剪樹
prune.tree=prune(churn.rp, cp=churn.cp)

plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)

predictions <-predict(prune.tree, testset,type = "class")
table(testset$churn, predictions)

install.packages('caret')
install.packages('e1071')
library('caret')
library('e1071')
#三大指標 Accuracy & precision & Sensitivity
confusionMatrix(table(testset$churn,predictions))
?confusionMatrix


```

## ctree
```{R}
# Ctree決策樹
install.packages("party")
library('party')
# 資料表trainset裡  除了churn以外的資料都建模存入ctree.model
ctree.model = ctree(churn ~ . , data = trainset)
plot(ctree.model, margin=0.1)
# 資料表trainset裡  除了churn選擇total_day_charge + international_plan建模存入daycharge.model
daycharge.model = ctree(churn ~ total_day_charge + international_plan, data = trainset)
plot(daycharge.model)


ctree.predict = predict(ctree.model ,testset)
# 二維統計 
table(ctree.predict, testset$churn)

confusionMatrix(table(ctree.predict, testset$churn))
```

## C5.0
```{R}
# C50 決策樹
install.packages("C50")
library(C50)
c50.model = C5.0(churn ~., data=trainset)

?C5.0Control

c=C5.0Control(minCases = 20)
c50.model = C5.0(churn ~., data=trainset,control = c)

summary(c50.model)
plot(c50.model)

c50.predict = predict(c50.model,testset)
table(c50.predict, testset$churn)

confusionMatrix(table(c50.predict, testset$churn))
```

## Estimating model performance with k-fold cross-validation
```{R}
#手作交叉驗證 cross-validation
ind = cut(1:nrow(churnTrain), breaks=10, labels=F)
ind

accuracies = c()
for (i in 1:10) {
  fit = rpart(formula=churn ~., data=churnTrain[ind != i,])
  predictions = predict(fit, churnTrain[ind == i, ! names(churnTrain) %in% c("churn")], type="class")
  correct_count = sum(predictions == churnTrain[ind == i,c("churn")])
  accuracies = append(correct_count / nrow(churnTrain[ind == i,]), accuracies)
}
accuracies
mean(accuracies)

```

## caret cross-validation
```{R}
#caret套件的train function 製作cross-validation
install.packages("caret")
library('caret')
control=trainControl(method="repeatedcv", number=10, repeats=3)
model =train(churn~., data=trainset, method="rpart", trControl=control)
model
predictions = predict(model, testset)

table(predictions,testset$churn)
confusionMatrix(table(predictions,testset$churn))
```

## find importance variable  
```{R}
library('caret')
#找出最重要的變數  summary也可以找  #summary(model)
importance = varImp(model, scale=FALSE)
importance
plot(importance)

```

## ROC
- https://www.youtube.com/watch?v=OAl6eAyP-yo
- http://www.navan.name/roc/

```{R}
install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc<-predictions[, 1]
head(pred.to.roc)
pred.rocr<-prediction(pred.to.roc, testset$churn)
pred.rocr
perf.rocr<-performance(pred.rocr, measure ="auc", x.measure="cutoff")
#ROC曲線(Sensitivity/ 1-specifitciy plots)
perf.tpr.rocr<-performance(pred.rocr, "tpr","fpr")
plot(perf.tpr.rocr,colorize=T)
plot(perf.tpr.rocr,colorize=T,main=paste("AUC:",(perf.rocr@y.values)))

#Precision/recall graphs
perf.tpr.rocr1<-performance(pred.rocr, "prec","rec")
plot(perf.tpr.rocr1,colorize=T)

#Sensitivity/specifitciy plots
perf.tpr.rocr2<-performance(pred.rocr, "sens","spec")
plot(perf.tpr.rocr2,colorize=T)

```

## model comparison
```{R}
#rpart
library('rpart')
churn.rp<-rpart(churn ~., data=trainset)

#ctree
#install.packages("party")
library('party')
ctree.model = ctree(churn ~ . , data = trainset)

#C5.0
library(C50)
c50.model = C5.0(churn ~., data=trainset)

rp.predict.prob = predict(churn.rp, testset,type='prob')
c50.predict.prob = predict(c50.model,testset,type='prob')
ctree.predict.prob = sapply(predict(ctree.model ,testset,type='prob'),function(e){unlist(e)[1]})
rp.prediction = prediction(rp.predict.prob[,1],testset$churn)
c50.prediction = prediction(c50.predict.prob[,1],testset$churn)
ctree.prediction = prediction(ctree.predict.prob,testset$churn)
rp.performance = performance(rp.prediction, "tpr","fpr")
c50.performance = performance(c50.prediction, "tpr","fpr")
ctree.performance = performance(ctree.prediction, "tpr","fpr")
plot(rp.performance,col='red')
plot(c50.performance, add=T,col='green')
plot(ctree.performance, add=T,col='blue')
```
